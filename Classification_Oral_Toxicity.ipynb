{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"><font color='gray' textalign='center'>Lab 3: Classification</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ds_functions as ds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('qsar_oral_toxicity.csv', sep = ';', header = None)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='gray'> Training Models </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ds_functions as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 1024\n",
    "positive = 'positive'\n",
    "negative = 'negative'\n",
    "values = {'Original': [len(data[data[target] == positive]), len(data[data[target] == negative])]}\n",
    "\n",
    "y: np.ndarray = data.pop(1024).values\n",
    "X: np.ndarray = data.values\n",
    "labels: np.ndarray = pd.unique(y)\n",
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnX, tstX, trnY, tstY = train_test_split(X, y, train_size=0.7, stratify=y)\n",
    "values['Train'] = [len(np.delete(trnY, np.argwhere(trnY==negative))), len(np.delete(trnY, np.argwhere(trnY==positive)))]\n",
    "values['Test'] = [len(np.delete(tstY, np.argwhere(tstY==negative))), len(np.delete(tstY, np.argwhere(tstY==positive)))]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "ds.multiple_bar_chart([positive, negative], values, title='Data distribution per dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(trnX, trnY)\n",
    "clf.score(tstX, tstY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "prdY: np.ndarray = clf.predict(tstX)\n",
    "cnf_mtx: np.ndarray = metrics.confusion_matrix(tstY, prdY, labels)\n",
    "cnf_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "CMAP = plt.cm.Blues\n",
    "\n",
    "def plot_confusion_matrix(cnf_matrix: np.ndarray, classes_names: np.ndarray, ax: plt.Axes = None,\n",
    "                          normalize: bool = False):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if normalize:\n",
    "        total = cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        cm = cnf_matrix.astype('float') / total\n",
    "        title = \"Normalized confusion matrix\"\n",
    "    else:\n",
    "        cm = cnf_matrix\n",
    "        title = 'Confusion matrix'\n",
    "    np.set_printoptions(precision=2)\n",
    "    tick_marks = np.arange(0, len(classes_names), 1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(classes_names)\n",
    "    ax.set_yticklabels(classes_names)\n",
    "    ax.imshow(cm, interpolation='nearest', cmap=CMAP)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, format(cm[i, j], fmt), color='w', horizontalalignment=\"center\")\n",
    "\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4), squeeze=False)\n",
    "plot_confusion_matrix(cnf_mtx, labels, ax=axs[0,0])\n",
    "plot_confusion_matrix(metrics.confusion_matrix(tstY, prdY, labels), labels, axs[0,1], normalize=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_chart(models: dict, tstX: np.ndarray, tstY: np.ndarray, ax: plt.Axes = None, target: str = 'class'):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.set_xlabel('FP rate')\n",
    "    ax.set_ylabel('TP rate')\n",
    "    ax.set_title('ROC chart for %s' % target)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], color='navy', label='random', linewidth=1, linestyle='--',  marker='')\n",
    "    for clf in models.keys():\n",
    "        metrics.plot_roc_curve(models[clf], tstX, tstY, ax=ax, marker='', linewidth=1)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "model = GaussianNB().fit(trnX, trnY)\n",
    "\n",
    "plt.figure()\n",
    "plot_roc_chart({'GaussianNB': model}, tstX, tstY, target='class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='gray'> Naive Bayes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "import ds_functions as ds\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(trnX, trnY)\n",
    "prd_trn = clf.predict(trnX)\n",
    "prd_tst = clf.predict(tstX)\n",
    "ds.plot_evaluation_results(labels, trnY, prd_trn, tstY, prd_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {'GaussianNB': GaussianNB(),\n",
    "              'MultinomialNB': MultinomialNB(),\n",
    "              'BernoulyNB': BernoulliNB()}\n",
    "\n",
    "xvalues = []\n",
    "yvalues = []\n",
    "for clf in estimators:\n",
    "    xvalues.append(clf)\n",
    "    estimators[clf].fit(trnX, trnY)\n",
    "    prdY = estimators[clf].predict(tstX)\n",
    "    yvalues.append(metrics.accuracy_score(tstY, prdY))\n",
    "\n",
    "plt.figure()\n",
    "ds.bar_chart(xvalues, yvalues, title='Comparison of Naive Bayes Models', ylabel='accuracy', percentage=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='gray'> KNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import ds_functions as ds\n",
    "\n",
    "nvalues = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "dist = ['manhattan', 'euclidean', 'chebyshev']\n",
    "values = {}\n",
    "train_values = {}\n",
    "best = (0, '')\n",
    "last_best = 0\n",
    "for d in dist:\n",
    "    yvalues = []\n",
    "    y_trn_values = []\n",
    "    for n in nvalues:\n",
    "        knn = KNeighborsClassifier(n_neighbors=n, metric=d)\n",
    "        knn.fit(trnX, trnY)\n",
    "        prdY = knn.predict(tstX)\n",
    "        prd_trn_Y = knn.predict(trnX)\n",
    "        yvalues.append(metrics.accuracy_score(tstY, prdY))\n",
    "        y_trn_values.append(metrics.accuracy_score(trnY, prd_trn_Y))\n",
    "        if yvalues[-1] > last_best:\n",
    "            best = (n, d)\n",
    "            last_best = yvalues[-1]\n",
    "    values[d] = yvalues\n",
    "    train_values[d] = y_trn_values\n",
    "\n",
    "plt.figure()\n",
    "ds.multiple_line_chart(nvalues, values, title='KNN variants', xlabel='n', ylabel='accuracy', percentage=True)\n",
    "plt.show()\n",
    "print('Best results with %d neighbors and %s'%(best[0], best[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = knn = KNeighborsClassifier(n_neighbors=best[0], metric=best[1])\n",
    "clf.fit(trnX, trnY)\n",
    "prd_trn = clf.predict(trnX)\n",
    "prd_tst = clf.predict(tstX)\n",
    "ds.plot_evaluation_results(labels, trnY, prd_trn, tstY, prd_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 4), squeeze=False)\n",
    "for i in range(len(dist)):\n",
    "    ds.multiple_line_chart(nvalues, {'train': train_values[dist[i]], 'test': values[dist[i]]}, ax=axs[0, i], title=dist[i], xlabel='n', ylabel='accuracy', percentage=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='gray'>Decision Trees</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "min_impurity_decrease = [0.025, 0.01, 0.005, 0.0025, 0.001]\n",
    "max_depths = [2, 5, 10, 15, 20, 25]\n",
    "criteria = ['entropy', 'gini']\n",
    "best = ('',  0, 0.0)\n",
    "last_best = 0\n",
    "best_tree = None\n",
    "\n",
    "criteria_test_values = {}\n",
    "criteria_train_values = {}\n",
    "\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 4), squeeze=False)\n",
    "for k in range(len(criteria)):\n",
    "    f = criteria[k]\n",
    "    values = {}\n",
    "    train_values = {}\n",
    "    for d in max_depths:\n",
    "        yvalues = []\n",
    "        y_trn_values = []\n",
    "        for imp in min_impurity_decrease:\n",
    "            tree = DecisionTreeClassifier(min_samples_leaf=n, max_depth=d, criterion=f, min_impurity_decrease=imp)\n",
    "            tree.fit(trnX, trnY)\n",
    "            prdY = tree.predict(tstX)\n",
    "            prd_trn_Y = tree.predict(trnX)\n",
    "            yvalues.append(metrics.accuracy_score(tstY, prdY))\n",
    "            y_trn_values.append(metrics.accuracy_score(trnY, prd_trn_Y))\n",
    "            if yvalues[-1] > last_best:\n",
    "                best = (f, d, imp)\n",
    "                last_best = yvalues[-1]\n",
    "                best_tree = tree\n",
    "\n",
    "        values[d] = yvalues\n",
    "        train_values[d] = y_trn_values\n",
    "    ds.multiple_line_chart(min_impurity_decrease, values, ax=axs[0, k], title='Decision Trees with %s criteria'%f,\n",
    "                           xlabel='min_impurity_decrease', ylabel='accuracy', percentage=True)\n",
    "    \n",
    "    criteria_test_values[f] = values\n",
    "    criteria_train_values[f] = train_values\n",
    "    \n",
    "\n",
    "plt.show()\n",
    "print('Best results achieved with %s criteria, depth=%d and min_impurity_decrease=%1.2f ==> accuracy=%1.2f'%(best[0], best[1], best[2], last_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "dot_data = export_graphviz(tree, out_file='dtree.dot', filled=True, rounded=True, special_characters=True)\n",
    "# Convert to png\n",
    "(graph,) = pydot.graph_from_dot_file('dtree.dot')\n",
    "graph.write_png('dtree.png')\n",
    "\n",
    "plt.figure(figsize = (14, 18))\n",
    "plt.imshow(plt.imread('dtree.png'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_trn = best_tree.predict(trnX)\n",
    "prd_tst = best_tree.predict(tstX)\n",
    "ds.plot_evaluation_results(labels, trnY, prd_trn, tstY, prd_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(criteria)):\n",
    "    train_values = criteria_train_values[criteria[j]]\n",
    "    test_values = criteria_test_values[criteria[j]]\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(16, 4), squeeze=False)\n",
    "    for i in range(len(max_depths)):\n",
    "        ds.multiple_line_chart(min_impurity_decrease, {'train': train_values[max_depths[i]], 'test': test_values[max_depths[i]]}, ax=axs[int(i/3), i%3], title='Criteria: ' + criteria[j]+ ', depth: ' + str(max_depths[i]), xlabel='min impurity decrease', ylabel='accuracy', percentage=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
